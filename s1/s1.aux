\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrturl}
\citation{gostic2020,thompson2019}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Simulation}{1}{section.2}\protected@file@percent }
\newlabel{eq:simulation-setup}{{{1}}{1}{Simulation}{AMS.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simulated set of 100 infectivity profiles generated by the R package `EpiEstim`, using mean of 5 ($\pm $ 1) days and sd of 3 ($\pm $ 1) days, as an offset gamma distribution, discretised on daily intervals, and truncated at 14 days. The average of these infectivity profiles is regarded as the ``true'' value and is highlighted in blue. }}{2}{figure.1}\protected@file@percent }
\newlabel{fig:S1}{{1}{2}{A simulated set of 100 infectivity profiles generated by the R package `EpiEstim`, using mean of 5 ($\pm $ 1) days and sd of 3 ($\pm $ 1) days, as an offset gamma distribution, discretised on daily intervals, and truncated at 14 days. The average of these infectivity profiles is regarded as the ``true'' value and is highlighted in blue}{figure.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameters of a Beta distribution ($\alpha $ and $\beta $) which decide the day to day ascertainment rate of the simulations ($P_{asc}$)}}{2}{table.1}\protected@file@percent }
\newlabel{eq:simulation-setup-2}{{{2}}{2}{Simulation}{AMS.2}{}}
\citation{gostic2020,parag2021}
\@writefile{toc}{\contentsline {section}{\numberline {3}Validation}{3}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Lags in $R_t$ estimation methods. `EpiEstim' integrates information over a window, during which $R_t$ is assumed constant. By convention the timepoint for the estimate is taken to be the end of the window and therefore the estimate is lagged (left panel). The $R_t$ from modelled incidence method described here is only affected by delays in the incidence estimation but the method we chose is not lagged (right panel).}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:S2}{{2}{3}{Lags in $R_t$ estimation methods. `EpiEstim' integrates information over a window, during which $R_t$ is assumed constant. By convention the timepoint for the estimate is taken to be the end of the window and therefore the estimate is lagged (left panel). The $R_t$ from modelled incidence method described here is only affected by delays in the incidence estimation but the method we chose is not lagged (right panel)}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The five scenarios tested. Each scenario (rows) had 50 replications and 3 levels of ascertainment with different dispesion applied to them (columns). The coloured traces show the replicate resulting in the highest and lowest $R_t$ estimates for each scenario, for each method. }}{4}{figure.3}\protected@file@percent }
\newlabel{fig:S3}{{3}{4}{The five scenarios tested. Each scenario (rows) had 50 replications and 3 levels of ascertainment with different dispesion applied to them (columns). The coloured traces show the replicate resulting in the highest and lowest $R_t$ estimates for each scenario, for each method}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Additional results}{5}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Mean Continuous Ranked Probability Scores (panel A), proportional bias as a percent (panel B), 50\% prediction interval width (panel C), 50\% coverage probability (panel D) and Probability integral transform (PIT) histogram Wasserstein distance from uniform (Panel E), stratified by scenario and ascertainment noise. Lower values are better in all metrics apart from the 50\% coverage probability (panel D) which is ideally 0.5. Lower values of the prediction interval width are only unequivocally better in an unbiased and well calibrated estimator, otherwise a tradeoff between sharpness, bias and calibration is required.}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:S4}{{4}{6}{Mean Continuous Ranked Probability Scores (panel A), proportional bias as a percent (panel B), 50\% prediction interval width (panel C), 50\% coverage probability (panel D) and Probability integral transform (PIT) histogram Wasserstein distance from uniform (Panel E), stratified by scenario and ascertainment noise. Lower values are better in all metrics apart from the 50\% coverage probability (panel D) which is ideally 0.5. Lower values of the prediction interval width are only unequivocally better in an unbiased and well calibrated estimator, otherwise a tradeoff between sharpness, bias and calibration is required}{figure.4}{}}
\bibdata{../main/refs}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sensitivity analyses}{7}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sensitivity analysis of `EpiEstim', and `$R_t$ from incidence' estimates derived from 7 day data windows, as opposed to 14, as described in the main paper, and are shown in Panel A for each of 5 scenarios (highest and lowest replicates only). The figure compares the continuous ranked probability score (CRPS) - lower is better, panel B; the average proportional bias, and mean universal residuals which characterise bias, in panel C and D - lower is better; The 50\% prediction interval width measures estimator sharpness and lower is better if the estimator is unbiased and well calibrated (panel E); the probability of 50\% coverage (ideal value is 0.5, panel F), and adjusted probability integral transform (PIT) Wasserstein metric (lower is better, panel G) }}{8}{figure.5}\protected@file@percent }
\newlabel{fig:S5}{{5}{8}{Sensitivity analysis of `EpiEstim', and `$R_t$ from incidence' estimates derived from 7 day data windows, as opposed to 14, as described in the main paper, and are shown in Panel A for each of 5 scenarios (highest and lowest replicates only). The figure compares the continuous ranked probability score (CRPS) - lower is better, panel B; the average proportional bias, and mean universal residuals which characterise bias, in panel C and D - lower is better; The 50\% prediction interval width measures estimator sharpness and lower is better if the estimator is unbiased and well calibrated (panel E); the probability of 50\% coverage (ideal value is 0.5, panel F), and adjusted probability integral transform (PIT) Wasserstein metric (lower is better, panel G)}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sensitivity analysis of `EpiEstim', and `$R_t$ from incidence' estimates when neither estimate is corrected for lag, are shown in Panel A for each of 5 scenarios (highest and lowest replicates only). The figure compares the continuous ranked probability score (CRPS) - lower is better, panel B; the average proportional bias, and mean universal residuals which characterise bias, in panel C and D - lower is better; The 50\% prediction interval width measures estimator sharpness and lower is better if the estimator is unbiased and well calibrated (panel E); the probability of 50\% coverage (ideal value is 0.5, panel F), and adjusted probability integral transform (PIT) Wasserstein metric (lower is better, panel G) }}{9}{figure.6}\protected@file@percent }
\newlabel{fig:S6}{{6}{9}{Sensitivity analysis of `EpiEstim', and `$R_t$ from incidence' estimates when neither estimate is corrected for lag, are shown in Panel A for each of 5 scenarios (highest and lowest replicates only). The figure compares the continuous ranked probability score (CRPS) - lower is better, panel B; the average proportional bias, and mean universal residuals which characterise bias, in panel C and D - lower is better; The 50\% prediction interval width measures estimator sharpness and lower is better if the estimator is unbiased and well calibrated (panel E); the probability of 50\% coverage (ideal value is 0.5, panel F), and adjusted probability integral transform (PIT) Wasserstein metric (lower is better, panel G)}{figure.6}{}}
\bibcite{gostic2020}{{1}{}{{}}{{}}}
\bibcite{thompson2019}{{2}{}{{}}{{}}}
\bibcite{parag2021}{{3}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{10}

\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plos2015}
\citation{gostic2020}
\citation{davies2021}
\citation{vegvari2022}
\citation{gostic2020}
\citation{cori2013,thompson2019}
\citation{abbott2024,alvarez2021,parag2021,thompson2019,wallinga2006,steyn2024,nash2023,nash2022,gressani2022,cauchemez2006,hong2020,johnson2021,ogi-gittins2024}
\citation{abbott2020}
\citation{gostic2020,park2021}
\citation{park2021,thompson2019}
\citation{thompson2019}
\citation{gostic2020}
\citation{lo2013}
\newlabel{eq:renew}{{2}{3}{Mathematical analysis}{equation.0.2}{}}
\newlabel{eq:lo}{{3}{3}{Mathematical analysis}{equation.0.3}{}}
\citation{hastie2017,rue2009}
\citation{wood2017}
\citation{blanchard2021}
\newlabel{eq:final}{{5}{4}{Mathematical analysis}{equation.0.5}{}}
\newlabel{eq:logsumexp}{{6}{5}{Numerical stability}{equation.0.6}{}}
\newlabel{eq:final_2}{{7}{5}{Infectivity profile uncertainty}{equation.0.7}{}}
\newlabel{eq:final_3}{{8}{5}{Infectivity profile uncertainty}{equation.0.8}{}}
\newlabel{eq:final_4}{{9}{6}{Infectivity profile uncertainty}{equation.0.9}{}}
\citation{loader1999}
\citation{loader2020}
\citation{wood2017}
\citation{anderson1996,bosse2024,bosse2023,brocker2008,gneiting2007}
\citation{panaretos2019}
\citation{david1948,hamill2001,wilks2019,brockwell2007}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces {\bf  Estimator delays in the validation scenarios}}}{8}{table.caption.11}\protected@file@percent }
\newlabel{tab1}{{1}{8}{\bf Estimator delays in the validation scenarios}{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\bf  Instantaneous reproduction number estimates from a branching process model simulation.} A qualitative comparison of instantaneous reproduction number estimates is shown. Panel A shows three case time series based on a single run of a branching process model parametrised with a stepped reproduction number time series (red lines in panel B) and infectivity profile as in \nameref {S1_Appendix} Fig S1. Case counts are shown as dots. A smoothed estimate of the cases per day as a line with shaded 95\% confidence intervals, based on a simple Poisson regression model. All three time series have on average 70\% case ascertainment, however the day to day variability of ascertainment is parametrised as a Beta distributed random variable, with ``low'', ``medium'' and ``high'' relating to the coefficient of variation of the Beta distribution (see \nameref {S1_Appendix} Table S1). Panel B shows estimates of the reproduction number based on the methods presented in this paper, and in the top row `EpiEstim` estimates derived from the data points in panel A are shown. In the middle row $R_t$ esimtates from a combination of GAM incidence model and the methods described in the paper. In the bottom row, $R_t$ estimates derived from a `Locfit' incidence model. In panel B the parametrised $R_t$ is shown as a solid red line and can be regarded as the ground truth for this single simulation run.}}{9}{figure.caption.10}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{9}{{\bf Instantaneous reproduction number estimates from a branching process model simulation.} A qualitative comparison of instantaneous reproduction number estimates is shown. Panel A shows three case time series based on a single run of a branching process model parametrised with a stepped reproduction number time series (red lines in panel B) and infectivity profile as in \nameref {S1_Appendix} Fig S1. Case counts are shown as dots. A smoothed estimate of the cases per day as a line with shaded 95\% confidence intervals, based on a simple Poisson regression model. All three time series have on average 70\% case ascertainment, however the day to day variability of ascertainment is parametrised as a Beta distributed random variable, with ``low'', ``medium'' and ``high'' relating to the coefficient of variation of the Beta distribution (see \nameref {S1_Appendix} Table S1). Panel B shows estimates of the reproduction number based on the methods presented in this paper, and in the top row `EpiEstim` estimates derived from the data points in panel A are shown. In the middle row $R_t$ esimtates from a combination of GAM incidence model and the methods described in the paper. In the bottom row, $R_t$ estimates derived from a `Locfit' incidence model. In panel B the parametrised $R_t$ is shown as a solid red line and can be regarded as the ground truth for this single simulation run}{figure.caption.10}{}}
\citation{thompson2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\bf  Quantitative comparison of $R_t$ estimation methods applied to 50 simulations of 5 scenarios at 3 levels of ascertainment noise.} The figure compares metrics describing the overall performance of the estimators. In Panel A is the continuous ranked probability score (CRPS) - lower is better; the average proportional bias (panel B) which characterise bias - lower is better; In panel C, the 50\% prediction interval width measures estimator sharpness, and lower is better if the estimator is unbiased and well calibrated. In Panel D the probability of 50\% coverage (ideal value is 0.5), and in Panel E the adjusted probability integral transform (PIT) Wasserstein metric (lower is better) are both measures of calibration. In Panel F a functional metric which quantifies the probability that an estimate is the wrong side of the cirtical threshold of $R_t=1$ desribes utility in decision making.}}{10}{figure.caption.12}\protected@file@percent }
\newlabel{fig2}{{2}{10}{{\bf Quantitative comparison of $R_t$ estimation methods applied to 50 simulations of 5 scenarios at 3 levels of ascertainment noise.} The figure compares metrics describing the overall performance of the estimators. In Panel A is the continuous ranked probability score (CRPS) - lower is better; the average proportional bias (panel B) which characterise bias - lower is better; In panel C, the 50\% prediction interval width measures estimator sharpness, and lower is better if the estimator is unbiased and well calibrated. In Panel D the probability of 50\% coverage (ideal value is 0.5), and in Panel E the adjusted probability integral transform (PIT) Wasserstein metric (lower is better) are both measures of calibration. In Panel F a functional metric which quantifies the probability that an estimate is the wrong side of the cirtical threshold of $R_t=1$ desribes utility in decision making}{figure.caption.12}{}}
\citation{gressani2022}
\citation{nelder1972,loader1999,hastie2017}
\citation{rue2009}
\citation{nash2023}
\citation{park2021}
\citation{abbott2020,abbott2024}
\bibdata{refs}
\bibcite{gostic2020}{1}
\bibcite{davies2021}{2}
\bibcite{vegvari2022}{3}
\bibcite{cori2013}{4}
\bibcite{thompson2019}{5}
\bibcite{abbott2024}{6}
\bibcite{alvarez2021}{7}
\bibcite{parag2021}{8}
\bibcite{wallinga2006}{9}
\bibcite{steyn2024}{10}
\bibcite{nash2023}{11}
\bibcite{nash2022}{12}
\bibcite{gressani2022}{13}
\bibcite{cauchemez2006}{14}
\bibcite{hong2020}{15}
\bibcite{johnson2021}{16}
\bibcite{ogi-gittins2024}{17}
\bibcite{abbott2020}{18}
\bibcite{park2021}{19}
\bibcite{lo2013}{20}
\bibcite{hastie2017}{21}
\bibcite{rue2009}{22}
\bibcite{wood2017}{23}
\bibcite{blanchard2021}{24}
\bibcite{loader1999}{25}
\bibcite{loader2020}{26}
\bibcite{anderson1996}{27}
\bibcite{bosse2024}{28}
\bibcite{bosse2023}{29}
\bibcite{brocker2008}{30}
\bibcite{gneiting2007}{31}
\bibcite{panaretos2019}{32}
\bibcite{david1948}{33}
\bibcite{hamill2001}{34}
\bibcite{wilks2019}{35}
\bibcite{brockwell2007}{36}
\bibcite{nelder1972}{37}
\newlabel{S1_Appendix}{{}{15}{S1 Appendix}{section*.21}{}}
\newlabel{S2_Appendix}{{}{15}{S2 Appendix}{section*.22}{}}
\newlabel{S3_Appendix}{{}{15}{S3 Appendix}{section*.23}{}}
\newlabel{LastPage}{{}{15}{S3 Appendix.}{page.15}{}}
\gdef\lastpage@lastpage{15}
\gdef\lastpage@lastpageHy{15}
\gdef \@abspage@last{15}
